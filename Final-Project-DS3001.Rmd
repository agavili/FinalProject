---
title: "Final-Project"
author: "Anna Stein, Tatev Gomstyan, Aishwarya Gavili"
date: "12/1/2021"
output:
  html_document:
    toc: yes
    theme: journal
    toc_float: yes
  pdf_document:
    toc: yes
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```

```{r, echo = F, results = 'hide', messages='hide'}
suppressMessages(library(tidyverse))
#install.packages("tidytext")
library(tidytext)
#install.packages("ggwordcloud")
library(ggwordcloud)
#install.packages("gutenbergr") 
library(gutenbergr)
#install.packages('textdata')
library(textdata)
#save.image("tidytext.RData")
```

Question: Are verified users more likely to show stronger sentiments towards the vaccine or toned down sentiments towards the vaccine?  Since most verified users are public figures, they may be either very vocal on their opinions regarding such a controversial topic or filter themselves to please the public or their followers. Consequently by doing the analysis below, we are trying to figure out whether their tweets reflect very strong sentiments through strong and persuasive language or whether their tweets are very general and not too political towards the topic of COVID vaccines.  Similarly, we are trying to see verified users showed more positive sentiments as a whole in comparison to unverified users.


# Data cleaning

```{r}
# import data
vax_data = read.csv("/Users/Student/Desktop/covidvaccine.csv")
View(vax_data)
```

Here, we took 10% of the dataframe to use for this project. This is a much more manageable number of observations.
```{r}
# the dataframe currently has over 300,000 observations. This is a massive dataframe. We don't need that many rows. 
vax_data = vax_data[(1:30000),]
# took 10% of the dataframe 
```


```{r}
# can take out username
# can take out location: since users are inputting their own locations, the data here is not easily organizable
# user description: another thing that users input for themselves. 
# can take out user-created, user followers, user friends, user favorites, source, is_retweet
# ^ can take these out because they aren't the actual text of the tweet 
vax_data = vax_data[,c(-1,-2,-3,-4,-5,-6,-7,-9,-11,-12,-13)]
# now its just the text of the tweet, and whether or not the user is verified 

str(vax_data) # both columns are characters

# split into 2 dataframes: verified users and non-verified users (?)
ver_vax = vax_data[vax_data$user_verified == "True",]
# dataframe of all verified users 
  
  
nonver_vax = vax_data[vax_data$user_verified == "False",]
# only tweets from non-verified users
```

```{r}
ver_vax <- ver_vax %>%
  unnest_tokens(word, text)%>%
  anti_join(stop_words)%>% # took out stop words
  count(word, sort=TRUE)
# this broke up the tweets by verified users into words 
# should we take out the numbers? 

nonver_vax <- nonver_vax %>%
  unnest_tokens(word, text)%>%
  anti_join(stop_words)%>% 
  count(word, sort=TRUE)

```

# Sentiment Analysis

```{r}
get_sentiments('afinn') # number scale from negative to positive 
get_sentiments('bing') # negative and positive 
get_sentiments('nrc') # more nuanced sentiment labels
```

# Verified users
```{r}
# We are going to run all 3 forms of sentiment analysis for tweets from verified users, and then tweets from unverified users. 

# Tweets from verified users: 
ver_sent_affin <- ver_vax %>%
  inner_join(get_sentiments("afinn"))
table(ver_sent_affin$value)


ver_sent_bing <- ver_vax%>%
  inner_join(get_sentiments("bing"))
table(ver_sent_bing$sentiment)


ver_sent_nrc <- ver_vax%>%
  inner_join(get_sentiments("nrc"))
table(ver_sent_nrc$sentiment)

```

```{r}
#remove duplicate words 
ver_sent_nrc_cleaned <- ver_sent_nrc[!duplicated(ver_sent_nrc$word), ]
```

## Plots 

### Histograms

#### Affin
```{r}
# Lets look at the sentiment analysis

ggplot(data = ver_sent_affin, 
       aes(x=value)
        )+
  geom_histogram()+
  ggtitle("Verified Tweets Sentiment Range")+
  theme_minimal()+theme(plot.title = element_text(hjust = 0.5))

```

#### NRC (1) 

```{r}
ggplot(data = ver_sent_nrc, 
       aes(x=sentiment)
        )+
  geom_histogram(stat="count")+
  ggtitle("Verified Tweets Sentiment Frequency")+
  theme_minimal()+theme(plot.title = element_text(hjust = 0.5))

```


#### NRC (2)
```{r}
numwords_per_sentiment_ver <- aggregate(ver_sent_nrc_cleaned$n, by=list(Sentiment=ver_sent_nrc_cleaned$sentiment), FUN=sum)

ggplot(data = numwords_per_sentiment_ver, 
       aes(x=Sentiment, y=x)
        )+
  geom_bar(stat="identity")+
  ggtitle("Total number of Words vs Sentiment (Verified)")+
  theme_minimal() + labs(y ="Number of Words")+theme(plot.title = element_text(hjust = 0.5))

```

### Wordclouds

```{r}

set.seed(42)
ggplot(ver_sent_nrc_cleaned[1:50,], aes(label = word, size = n, color = sentiment)
       ) +
  geom_text_wordcloud(show.legend = TRUE) +
  theme_minimal()+ggtitle("Unverified")+theme(plot.title = element_text(hjust = 0.5))

```

# Unverified users 

```{r}
# Tweets from unverified users: 
nonver_sent_affin <- nonver_vax %>%
  inner_join(get_sentiments("afinn"))
table(nonver_sent_affin$value)

nonver_sent_bing <- nonver_vax%>%
  inner_join(get_sentiments("bing"))
table(nonver_sent_bing$sentiment)


nonver_sent_nrc <- nonver_vax%>%
  inner_join(get_sentiments("nrc"))
table(nonver_sent_nrc$sentiment)



```

```{r}
#remove duplicate words 
nonver_sent_nrc_cleaned <- nonver_sent_nrc[!duplicated(nonver_sent_nrc$word), ]

```


## Plots 

### Histograms

#### Affin
```{r}
ggplot(data = nonver_sent_affin, 
       aes(x=value)
        )+
  geom_histogram()+
  ggtitle("Unverified Tweets Sentiment Range")+
  theme_minimal()+theme(plot.title = element_text(hjust = 0.5))
```

#### NRC (1)

```{r}
ggplot(data = nonver_sent_nrc, 
       aes(x=sentiment)
        )+
  geom_histogram(stat="count")+
  ggtitle("Unverified Tweets Sentiment Frequency")+
  theme_minimal()+theme(plot.title = element_text(hjust = 0.5))

```

#### NRC (2)

```{r}
numwords_per_sentiment_nonver <- aggregate(nonver_sent_nrc_cleaned$n, by=list(Sentiment=nonver_sent_nrc_cleaned$sentiment), FUN=sum)

ggplot(data = numwords_per_sentiment_nonver, 
       aes(x=Sentiment, y=x)
        )+
  geom_bar(stat="identity")+
  ggtitle("Total number of Words vs Sentiment (Unverified)")+
  theme_minimal() + labs(y ="Number of Words")+theme(plot.title = element_text(hjust = 0.5))

```

### Wordcloud
```{r}

set.seed(42)
ggplot(nonver_sent_nrc_cleaned[1:50,], aes(label = word,  size = n,color = sentiment)) +
  geom_text_wordcloud(show.legend = TRUE) +
  theme_minimal()+ggtitle("Unverified")+theme(plot.title = element_text(hjust = 0.5))

#alot of anticipation and political bc election
```

```{r}
View(vax_data)
vax_data_verified <- vax_data[vax_data$user_verified == "True",]
vax_data_verified_clean <- tibble(tweet = vax_data_verified[,2])
vax_data_unverified <- vax_data[vax_data$user_verified == "False",]
vax_data_unverified_clean <- tibble(tweet = vax_data_unverified[,2])

```

```{r}
#Tf-idf
#Here we are going to treat each of our tweets as a document in a corpus and explore the relative importance of words to these tweets as compared to the overall corpus. 

#pulling up raw data 

#write.csv(vax_data_verified_clean,"/Users/Student/Desktop//vervax.csv", row.names = FALSE )
#write.csv(vax_data_unverified_clean,"/Users/Student/Desktop//nonvervax.csv", row.names = FALSE )

ver_raw <- vax_data_verified_clean #as.tibble(read_lines("/Users/Student/Desktop//vervax.csv"))
nonver_raw <- vax_data_unverified_clean #as.tibble(read_lines("/Users/Student/Desktop//nonvervax.csv"))

data_prep <- function(x,y,z){
  i <- as_tibble(t(x))#transposing the data set
  ii <- unite(i,"text",y:z,remove = TRUE,sep = "")
}

#get rid of NAs/keep only alphanumeric values
#

#nonver_vax$word = gsub("[^[:alnum:]]", "", nonver_vax$word)

ver_vax_bag <- data_prep(ver_raw,'V1','V2174')
ver_vax_bag$text <- gsub("[^[:alnum:][:space:]]", "", ver_vax_bag$text)
  
label <- "verified"
ver_vax_1 <- tibble(label,ver_vax)

ver_vax_1$word = gsub("[^[:alnum:]]", "", ver_vax_1$word)
ver_vax_1 <- ver_vax_1[-c(1, 2, 6, 7, 17), ]

nonver_vax_bag <- data_prep(nonver_raw, 'V1','V27823')
nonver_vax_bag$text <- gsub("[^[:alnum:][:space:]]", "", nonver_vax_bag$text)

label <- "unverified"
nonver_vax1 <- tibble(label, nonver_vax)

nonver_vax1$word = gsub("[^[:alnum:]]", "", nonver_vax1$word)
nonver_vax1 <- nonver_vax1[-c(1, 2, 6, 7, 17, 19, 20), ]

xxx <- rbind(ver_vax_1,nonver_vax1)

verification <- c("Verified", "Unverified")

tf_idf_text_1 <- tibble(verification,text=t(tibble(ver_vax_bag,nonver_vax_bag,.name_repair = "universal")))

word_count <- tf_idf_text_1 %>%
  unnest_tokens(word, text) %>%
  count(verification, word, sort = TRUE)

total_words <- word_count %>% 
  group_by(verification) %>% 
  summarize(total = sum(n))

tweets <- inner_join(word_count, total_words)

tweets <- tweets %>%
  bind_tf_idf(word, verification, n)


```


# Summary

Background and Previous Research: 
Previous research: Misinformation relating to COVID-19 and the COVID-19 vaccine has been a salient issue since the onset of the pandemic. One major way that this misinformation has spread has been through social media channels such as Facebook and Twitter. In 2020, BBC reported that “social media has been a fertile ground for [Covid-19] conspiracy theories”(https://www.littlelaw.co.uk/2021/01/16/littlelaw-looks-atmisinformation-and-the-covid-19-vaccine/). 

Having been aware of this as users of social media, we decided to examine a dataset of Tweets from 2020 relating to the COVID-19 vaccine. We wanted to see if there are differences in sentiment towards the vaccine among different groups (verified v non-verified individuals). We figured that sentiment analysis, paired with our background knowledge and other research on the topic, could prove to be a useful tool in diving further into the types of narratives being spread on social media, regarding COVID-19 vaccines. 

Methods:
We began with a dataframe of over 300,000 tweets that contain the hashtag: #CovidVaccine. We decided that we won’t need nearly 300,000 rows for our analysis - this would be far too computationally expensive. We decided to cut down our dataset to 30,000 rows, essentially by 10%. We did some data cleaning, and took out the columns we didn’t need. We moved forward with only the columns that contain the Tweet text, and one that states whether or not the user is verified on Twitter. We made 2 dataframes: one for verified users, and one for unverified users. W e used 3 different types of sentiment analysis. We decided to do this so that we could represent the sentiments both numerically and categorically, as well as examine sentiments of different strengths. For example, we could use simple negative/positive categories for each word in the Tweets, or we could look at a range of sentiments, such as joy, fear, anticipation, etc. 
Once we performed the sentiment analysis, we decided to create graphs to help visualize the output. We created histograms and wordclouds. 

Fairness Assessment: 
We do not believe that we need to conduct a fairness assessment for this project. The classes we used here are verified vs. unverified Twitter users, which is not a protected class in society.

# Analysis 







