---
title: "Final-Project"
author: "Anna Stein, Tatev Gomstyan, Aishwarya Gavili"
date: "12/1/2021"
output:
  html_document:
    toc: yes
    theme: journal
    toc_float: yes
  pdf_document:
    toc: yes
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```

```{r, echo = F, results = 'hide', messages='hide'}
suppressMessages(library(tidyverse))
#install.packages("tidytext")
library(tidytext)
#install.packages("ggwordcloud")
library(ggwordcloud)
#install.packages("gutenbergr") 
library(gutenbergr)
#install.packages('textdata')
library(textdata)
#save.image("tidytext.RData")
```

Question: Are verified users more likely to show stronger sentiments towards the vaccine or toned down sentiments towards the vaccine?  Since most verified users are public figures, they may be either very vocal on their opinions regarding such a controversial topic or filter themselves to please the public or their followers. Consequently by doing the analysis below, we are trying to figure out whether their tweets reflect very strong sentiments through strong and persuasive language or whether their tweets are very general and not too political towards the topic of COVID vaccines.  Similarly, we are trying to see verified users showed more positive sentiments as a whole in comparison to unverified users.


# Data cleaning

```{r}
# import data
vax_data = read.csv("/Users/aishgav/Desktop/ds3001/covidvaccine.csv")
```

Here, we took 10% of the dataframe to use for this project. This is a much more manageable number of observations.
```{r}
# the dataframe currently has over 300,000 observations. This is a massive dataframe. We don't need that many rows. 
vax_data = vax_data[(1:30000),]
# took 10% of the dataframe 
```


```{r}
# can take out username
# can take out location: since users are inputting their own locations, the data here is not easily organizable
# user description: another thing that users input for themselves. 
# can take out user-created, user followers, user friends, user favorites, source, is_retweet
# ^ can take these out because they aren't the actual text of the tweet 
vax_data = vax_data[,c(-1,-2,-3,-4,-5,-6,-7,-9,-11,-12,-13)]
# now its just the text of the tweet, and whether or not the user is verified 

str(vax_data) # both columns are characters

# split into 2 dataframes: verified users and non-verified users (?)
ver_vax = vax_data[vax_data$user_verified == "True",]
# dataframe of all verified users 
  
  
nonver_vax = vax_data[vax_data$user_verified == "False",]
# only tweets from non-verified users
```

```{r}
ver_vax <- ver_vax %>%
  unnest_tokens(word, text)%>%
  anti_join(stop_words)%>% # took out stop words
  count(word, sort=TRUE)
# this broke up the tweets by verified users into words 
# should we take out the numbers? 

nonver_vax <- nonver_vax %>%
  unnest_tokens(word, text)%>%
  anti_join(stop_words)%>% 
  count(word, sort=TRUE)

```

# Sentiment Analysis

```{r}
get_sentiments('afinn') # number scale from negative to positive 
get_sentiments('bing') # negative and positive 
get_sentiments('nrc') # more nuanced sentiment labels
```

# Verified users
```{r}
# We are going to run all 3 forms of sentiment analysis for tweets from verified users, and then tweets from unverified users. 

# Tweets from verified users: 
ver_sent_affin <- ver_vax %>%
  inner_join(get_sentiments("afinn"))
table(ver_sent_affin$value)


ver_sent_bing <- ver_vax%>%
  inner_join(get_sentiments("bing"))
table(ver_sent_bing$sentiment)


ver_sent_nrc <- ver_vax%>%
  inner_join(get_sentiments("nrc"))
table(ver_sent_nrc$sentiment)

```

```{r}
#remove duplicate words 
ver_sent_nrc_cleaned <- ver_sent_nrc[!duplicated(ver_sent_nrc$word), ]
```

## Plots 

### Histograms

#### Affin
```{r}
# Lets look at the sentiment analysis

ggplot(data = ver_sent_affin, 
       aes(x=value)
        )+
  geom_histogram()+
  ggtitle("Verified Tweets Sentiment Range")+
  theme_minimal()+theme(plot.title = element_text(hjust = 0.5))

```

#### NRC (1) 

```{r}
ggplot(data = ver_sent_nrc, 
       aes(x=sentiment)
        )+
  geom_histogram(stat="count")+
  ggtitle("Verified Tweets Sentiment Frequency")+
  theme_minimal()+theme(plot.title = element_text(hjust = 0.5))

```


#### NRC (2)
```{r}
numwords_per_sentiment_ver <- aggregate(ver_sent_nrc_cleaned$n, by=list(Sentiment=ver_sent_nrc_cleaned$sentiment), FUN=sum)

ggplot(data = numwords_per_sentiment_ver, 
       aes(x=Sentiment, y=x)
        )+
  geom_bar(stat="identity")+
  ggtitle("Total number of Words vs Sentiment (Verified)")+
  theme_minimal() + labs(y ="Number of Words")+theme(plot.title = element_text(hjust = 0.5))

```

### Wordclouds

```{r}

set.seed(42)
ggplot(ver_sent_nrc_cleaned[1:50,], aes(label = word, size = n, color = sentiment)
       ) +
  geom_text_wordcloud(show.legend = TRUE) +
  theme_minimal()+ggtitle("Unverified")+theme(plot.title = element_text(hjust = 0.5))

```

# Unverified users 

```{r}
# Tweets from unverified users: 
nonver_sent_affin <- nonver_vax %>%
  inner_join(get_sentiments("afinn"))
table(nonver_sent_affin$value)

nonver_sent_bing <- nonver_vax%>%
  inner_join(get_sentiments("bing"))
table(nonver_sent_bing$sentiment)


nonver_sent_nrc <- nonver_vax%>%
  inner_join(get_sentiments("nrc"))
table(nonver_sent_nrc$sentiment)



```

```{r}
#remove duplicate words 
nonver_sent_nrc_cleaned <- nonver_sent_nrc[!duplicated(nonver_sent_nrc$word), ]

```


## Plots 

### Histograms

#### Affin
```{r}
ggplot(data = nonver_sent_affin, 
       aes(x=value)
        )+
  geom_histogram()+
  ggtitle("Unverified Tweets Sentiment Range")+
  theme_minimal()+theme(plot.title = element_text(hjust = 0.5))
```

#### NRC (1)

```{r}
ggplot(data = nonver_sent_nrc, 
       aes(x=sentiment)
        )+
  geom_histogram(stat="count")+
  ggtitle("Unverified Tweets Sentiment Frequency")+
  theme_minimal()+theme(plot.title = element_text(hjust = 0.5))

```

#### NRC (2)

```{r}
numwords_per_sentiment_nonver <- aggregate(nonver_sent_nrc_cleaned$n, by=list(Sentiment=nonver_sent_nrc_cleaned$sentiment), FUN=sum)

ggplot(data = numwords_per_sentiment_nonver, 
       aes(x=Sentiment, y=x)
        )+
  geom_bar(stat="identity")+
  ggtitle("Total number of Words vs Sentiment (Unverified)")+
  theme_minimal() + labs(y ="Number of Words")+theme(plot.title = element_text(hjust = 0.5))

```

### Wordcloud
```{r}

set.seed(42)
ggplot(nonver_sent_nrc_cleaned[1:50,], aes(label = word,  size = n,color = sentiment)) +
  geom_text_wordcloud(show.legend = TRUE) +
  theme_minimal()+ggtitle("Unverified")+theme(plot.title = element_text(hjust = 0.5))

#alot of anticipation and political bc election
```

# Summary
